{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check Directories.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'Museum_Training/Training/' exists.\n"
     ]
    }
   ],
   "source": [
    "Train_dir = \"Museum_Training/Training/\"\n",
    "# Test_dir = \"Museum_Test/Museum_Validation/\"\n",
    "\n",
    "classification_targets = ['museum-indoor', 'museum-outdoor']\n",
    "\n",
    "def check_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"Directory '{directory}' exists.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' does NOT exist.\")\n",
    "\n",
    "check_directory(Train_dir)\n",
    "# check_directory(Test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "    return filename.lower().endswith(valid_extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-process images - greyscale.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grayscale Image Data Shape: (10000, 65536)\n",
      "Labels Shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_images_grayscale(target_dir, classes, image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocess images: Convert to grayscale, resize, and flatten.\n",
    "\n",
    "    Parameters:\n",
    "    - target_dir: Path to the target directory containing class folders.\n",
    "    - classes: List of class names.\n",
    "    - image_size: Target image size (width, height).\n",
    "\n",
    "    Returns:\n",
    "    - X_gray: Flattened grayscale image data.\n",
    "    - y_gray: Corresponding labels.\n",
    "    \"\"\"\n",
    "    X_grey = []\n",
    "    y_grey = []\n",
    "\n",
    "    for label, cls in enumerate(classes):\n",
    "        class_dir = os.path.join(target_dir, cls)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            if is_image_file(img_name):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                try:\n",
    "                    # Open Image\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img = img.convert('L')  \n",
    "                        img = img.resize(image_size)  \n",
    "                        img_array = np.array(img).flatten() \n",
    "\n",
    "                        X_grey.append(img_array)\n",
    "                        y_grey.append(label)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {img_path}: {e}\")\n",
    "\n",
    "    X_grey = np.array(X_grey)\n",
    "    y_grey = np.array(y_grey)\n",
    "    return X_grey, y_grey\n",
    "\n",
    "X_grey, y_grey = preprocess_images_grayscale(Train_dir, classification_targets)\n",
    "\n",
    "print(\"\\nGrayscale Image Data Shape:\", X_grey.shape)\n",
    "print(\"Labels Shape:\", y_grey.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split data to train and test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8000, 65536)\n",
      "Testing data shape: (2000, 65536)\n"
     ]
    }
   ],
   "source": [
    "X_grey_train, X_grey_test, y_grey_train, y_grey_test = train_test_split(X_grey, y_grey, test_size=0.2, random_state=42)\n",
    "print(\"Training data shape:\", X_grey_train.shape)\n",
    "print(\"Testing data shape:\", X_grey_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision tree algorithm with hyperparameters.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Metrics ---\n",
      "Accuracy: 0.730875\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.68      0.87      0.76      3988\n",
      "museum-outdoor       0.82      0.59      0.69      4012\n",
      "\n",
      "      accuracy                           0.73      8000\n",
      "     macro avg       0.75      0.73      0.73      8000\n",
      "  weighted avg       0.75      0.73      0.73      8000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3480  508]\n",
      " [1645 2367]]\n",
      "\n",
      "--- Testing Metrics ---\n",
      "Accuracy: 0.654\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.62      0.82      0.70      1012\n",
      "museum-outdoor       0.72      0.49      0.58       988\n",
      "\n",
      "      accuracy                           0.65      2000\n",
      "     macro avg       0.67      0.65      0.64      2000\n",
      "  weighted avg       0.67      0.65      0.64      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[825 187]\n",
      " [505 483]]\n"
     ]
    }
   ],
   "source": [
    "# Define and train model\n",
    "dt_model_entropy = DecisionTreeClassifier(criterion='entropy',max_depth=6,min_samples_split=2,random_state=42)\n",
    "dt_model_entropy.fit(X_grey_train, y_grey_train)\n",
    "\n",
    "y_train_pred = dt_model_entropy.predict(X_grey_train)\n",
    "y_test_pred = dt_model_entropy.predict(X_grey_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_grey_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_grey_test, y_test_pred)\n",
    "\n",
    "cm_train = confusion_matrix(y_grey_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_grey_test, y_test_pred)\n",
    "\n",
    "print('--- Training Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_train, y_train_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_train)\n",
    "print('\\n--- Testing Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_test, y_test_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Metrics ---\n",
      "Accuracy: 0.7265\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.73      0.73      0.73      3988\n",
      "museum-outdoor       0.73      0.73      0.73      4012\n",
      "\n",
      "      accuracy                           0.73      8000\n",
      "     macro avg       0.73      0.73      0.73      8000\n",
      "  weighted avg       0.73      0.73      0.73      8000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2893 1095]\n",
      " [1093 2919]]\n",
      "\n",
      "--- Testing Metrics ---\n",
      "Accuracy: 0.653\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.66      0.64      0.65      1012\n",
      "museum-outdoor       0.64      0.67      0.65       988\n",
      "\n",
      "      accuracy                           0.65      2000\n",
      "     macro avg       0.65      0.65      0.65      2000\n",
      "  weighted avg       0.65      0.65      0.65      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[648 364]\n",
      " [330 658]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_model_gini = DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_split=2,random_state=42)\n",
    "dt_model_gini.fit(X_grey_train, y_grey_train)\n",
    "\n",
    "y_train_pred = dt_model_gini.predict(X_grey_train)\n",
    "y_test_pred = dt_model_gini.predict(X_grey_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_grey_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_grey_test, y_test_pred)\n",
    "\n",
    "cm_train = confusion_matrix(y_grey_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_grey_test, y_test_pred)\n",
    "\n",
    "print('--- Training Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_train, y_train_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_train)\n",
    "print('\\n--- Testing Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_test, y_test_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest algorithm with hyperparameters.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Metrics ---\n",
      "Accuracy: 0.808625\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.82      0.79      0.80      3988\n",
      "museum-outdoor       0.80      0.83      0.81      4012\n",
      "\n",
      "      accuracy                           0.81      8000\n",
      "     macro avg       0.81      0.81      0.81      8000\n",
      "  weighted avg       0.81      0.81      0.81      8000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3158  830]\n",
      " [ 701 3311]]\n",
      "\n",
      "--- Testing Metrics ---\n",
      "Accuracy: 0.738\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.75      0.73      0.74      1012\n",
      "museum-outdoor       0.73      0.75      0.74       988\n",
      "\n",
      "      accuracy                           0.74      2000\n",
      "     macro avg       0.74      0.74      0.74      2000\n",
      "  weighted avg       0.74      0.74      0.74      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[737 275]\n",
      " [249 739]]\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(max_depth=6,n_estimators=100, criterion='entropy', random_state=42) \n",
    "rf_model.fit(X_grey_train, y_grey_train)\n",
    "\n",
    "y_train_pred = rf_model.predict(X_grey_train)\n",
    "y_test_pred = rf_model.predict(X_grey_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_grey_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_grey_test, y_test_pred)\n",
    "\n",
    "cm_train = confusion_matrix(y_grey_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_grey_test, y_test_pred)\n",
    "\n",
    "print('--- Training Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_train, y_train_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_train)\n",
    "print('\\n--- Testing Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_test, y_test_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Metrics ---\n",
      "Accuracy: 0.7765\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.80      0.74      0.77      3988\n",
      "museum-outdoor       0.76      0.81      0.79      4012\n",
      "\n",
      "      accuracy                           0.78      8000\n",
      "     macro avg       0.78      0.78      0.78      8000\n",
      "  weighted avg       0.78      0.78      0.78      8000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2944 1044]\n",
      " [ 744 3268]]\n",
      "\n",
      "--- Testing Metrics ---\n",
      "Accuracy: 0.714\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.74      0.67      0.70      1012\n",
      "museum-outdoor       0.69      0.76      0.72       988\n",
      "\n",
      "      accuracy                           0.71      2000\n",
      "     macro avg       0.72      0.71      0.71      2000\n",
      "  weighted avg       0.72      0.71      0.71      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[679 333]\n",
      " [239 749]]\n"
     ]
    }
   ],
   "source": [
    "rf_model_gini = RandomForestClassifier(max_depth=5,n_estimators=50, criterion='gini', random_state=42)  \n",
    "rf_model_gini.fit(X_grey_train, y_grey_train)\n",
    "\n",
    "y_train_pred = rf_model_gini.predict(X_grey_train)\n",
    "y_test_pred = rf_model_gini.predict(X_grey_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_grey_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_grey_test, y_test_pred)\n",
    "\n",
    "cm_train = confusion_matrix(y_grey_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_grey_test, y_test_pred)\n",
    "\n",
    "print('--- Training Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_train, y_train_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_train)\n",
    "print('\\n--- Testing Metrics ---')\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_test, y_test_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create pickle files to export the trained models.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"rf_model_grey.pkl\", \"wb\") as rf_model_grey:\n",
    "    pickle.dump(rf_model, rf_model_grey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dt_model_entropy_grey.pkl\", \"wb\") as dt_model_entropy_grey:\n",
    "    pickle.dump(dt_model_entropy, dt_model_entropy_grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-preocess images for Boosting algorithm.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grayscale Image Data Shape: (10000, 16384)\n",
      "Labels Shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_images_grayscale(target_dir, classes, image_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Preprocess images: Convert to grayscale, resize, and flatten.\n",
    "\n",
    "    Parameters:\n",
    "    - target_dir: Path to the target directory containing class folders.\n",
    "    - classes: List of class names.\n",
    "    - image_size: Target image size.\n",
    "\n",
    "    Returns:\n",
    "    - X_gray: Flattened grayscale image data.\n",
    "    - y_gray: Corresponding labels.\n",
    "    \"\"\"\n",
    "    X_grey128 = []\n",
    "    y_grey128 = []\n",
    "\n",
    "    for label, cls in enumerate(classes):\n",
    "        class_dir = os.path.join(target_dir, cls)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            if is_image_file(img_name):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                try:\n",
    "                    # Open Image\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img = img.convert('L')  \n",
    "                        img = img.resize(image_size) \n",
    "                        img_array = np.array(img).flatten() \n",
    "\n",
    "                        X_grey128.append(img_array)\n",
    "                        y_grey128.append(label)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {img_path}: {e}\")\n",
    "\n",
    "    X_grey128 = np.array(X_grey128)\n",
    "    y_grey128 = np.array(y_grey128)\n",
    "    return X_grey128, y_grey128\n",
    "\n",
    "X_grey128, y_grey128 = preprocess_images_grayscale(Train_dir, classification_targets)\n",
    "\n",
    "print(\"\\nGrayscale Image Data Shape:\", X_grey128.shape)\n",
    "print(\"Labels Shape:\", y_grey128.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8000, 16384)\n",
      "Testing data shape: (2000, 16384)\n"
     ]
    }
   ],
   "source": [
    "X_grey128_train, X_grey128_test, y_grey128_train, y_grey128_test = train_test_split(X_grey128, y_grey128, test_size=0.2, random_state=42)\n",
    "print(\"Training data shape:\", X_grey128_train.shape)\n",
    "print(\"Testing data shape:\", X_grey128_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XGBoost algorithm with different hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Training Metrics\n",
      "Accuracy: 0.910875\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.91      0.91      0.91      3988\n",
      "museum-outdoor       0.91      0.92      0.91      4012\n",
      "\n",
      "      accuracy                           0.91      8000\n",
      "     macro avg       0.91      0.91      0.91      8000\n",
      "  weighted avg       0.91      0.91      0.91      8000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3613  375]\n",
      " [ 338 3674]]\n",
      "\n",
      "XGBoost Testing Metrics\n",
      "Accuracy: 0.768\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.76      0.79      0.77      1012\n",
      "museum-outdoor       0.77      0.75      0.76       988\n",
      "\n",
      "      accuracy                           0.77      2000\n",
      "     macro avg       0.77      0.77      0.77      2000\n",
      "  weighted avg       0.77      0.77      0.77      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[795 217]\n",
      " [247 741]]\n"
     ]
    }
   ],
   "source": [
    "xgb_model_grey = xgb.XGBClassifier(max_depth=5, n_estimators=50, learning_rate=0.1, objective=\"multi:softmax\", random_state=42,num_class=2)\n",
    "xgb_model_grey.fit(X_grey128_train, y_grey128_train)\n",
    "\n",
    "\n",
    "y_train_pred_xgb = xgb_model_grey.predict(X_grey128_train)\n",
    "y_test_pred_xgb = xgb_model_grey.predict(X_grey128_test)\n",
    "\n",
    "\n",
    "accuracy_train_xgb = accuracy_score(y_grey128_train, y_train_pred_xgb)\n",
    "accuracy_test_xgb = accuracy_score(y_grey128_test, y_test_pred_xgb)\n",
    "\n",
    "\n",
    "cm_train_xgb = confusion_matrix(y_grey128_train, y_train_pred_xgb)\n",
    "cm_test_xgb = confusion_matrix(y_grey128_test, y_test_pred_xgb)\n",
    "\n",
    "\n",
    "print(\"\\nXGBoost Training Metrics\")\n",
    "print(\"Accuracy:\", accuracy_train_xgb)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey128_train, y_train_pred_xgb, target_names=classification_targets))\n",
    "print(\"Confusion Matrix:\\n\", cm_train_xgb)\n",
    "\n",
    "print(\"\\nXGBoost Testing Metrics\")\n",
    "print(\"Accuracy:\", accuracy_test_xgb)\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey128_test, y_test_pred_xgb, target_names=classification_targets))\n",
    "print(\"Confusion Matrix:\\n\", cm_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"xgb_model_grey.pkl\", \"wb\") as  xgb_model_grey_file:\n",
    "    pickle.dump(xgb_model_grey, xgb_model_grey_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Semi supervised decision tree algorithm on grey scaled image data.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration 1: Training on 1600 labeled samples.\n",
      " Test Accuracy after Iteration 1: 0.6423\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.64      0.63      0.64      3190\n",
      "museum-outdoor       0.64      0.65      0.65      3210\n",
      "\n",
      "      accuracy                           0.64      6400\n",
      "     macro avg       0.64      0.64      0.64      6400\n",
      "  weighted avg       0.64      0.64      0.64      6400\n",
      "\n",
      " Test Confusion Matrix after Iteration 1:\n",
      " [[2011 1179]\n",
      " [1110 2100]]\n",
      "3948 high-confidence samples added. New labeled size: 5548\n",
      "\n",
      " Iteration 2: Training on 5548 labeled samples.\n",
      " Test Accuracy after Iteration 2: 0.5665\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.54      0.66      0.60      1192\n",
      "museum-outdoor       0.60      0.48      0.53      1260\n",
      "\n",
      "      accuracy                           0.57      2452\n",
      "     macro avg       0.57      0.57      0.56      2452\n",
      "  weighted avg       0.57      0.57      0.56      2452\n",
      "\n",
      " Test Confusion Matrix after Iteration 2:\n",
      " [[784 408]\n",
      " [655 605]]\n",
      "837 high-confidence samples added. New labeled size: 6385\n",
      "\n",
      " Iteration 3: Training on 6385 labeled samples.\n",
      " Test Accuracy after Iteration 3: 0.4885\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.49      0.63      0.55       797\n",
      "museum-outdoor       0.49      0.35      0.41       818\n",
      "\n",
      "      accuracy                           0.49      1615\n",
      "     macro avg       0.49      0.49      0.48      1615\n",
      "  weighted avg       0.49      0.49      0.48      1615\n",
      "\n",
      " Test Confusion Matrix after Iteration 3:\n",
      " [[503 294]\n",
      " [532 286]]\n",
      "117 high-confidence samples added. New labeled size: 6502\n",
      "\n",
      " Iteration 4: Training on 6502 labeled samples.\n",
      " Test Accuracy after Iteration 4: 0.5013\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.49      0.72      0.59       735\n",
      "museum-outdoor       0.52      0.29      0.37       763\n",
      "\n",
      "      accuracy                           0.50      1498\n",
      "     macro avg       0.51      0.51      0.48      1498\n",
      "  weighted avg       0.51      0.50      0.48      1498\n",
      "\n",
      " Test Confusion Matrix after Iteration 4:\n",
      " [[531 204]\n",
      " [543 220]]\n",
      "153 high-confidence samples added. New labeled size: 6655\n",
      "\n",
      " Iteration 5: Training on 6655 labeled samples.\n",
      " Test Accuracy after Iteration 5: 0.4825\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.48      0.71      0.57       650\n",
      "museum-outdoor       0.50      0.27      0.35       695\n",
      "\n",
      "      accuracy                           0.48      1345\n",
      "     macro avg       0.49      0.49      0.46      1345\n",
      "  weighted avg       0.49      0.48      0.46      1345\n",
      "\n",
      " Test Confusion Matrix after Iteration 5:\n",
      " [[460 190]\n",
      " [506 189]]\n",
      "No confident pseudo-labels found. Stopping early.\n",
      "\n",
      "Final Testing Metrics\n",
      "Accuracy: 0.6280\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.63      0.64      0.63      1012\n",
      "museum-outdoor       0.62      0.62      0.62       988\n",
      "\n",
      "      accuracy                           0.63      2000\n",
      "     macro avg       0.63      0.63      0.63      2000\n",
      "  weighted avg       0.63      0.63      0.63      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[620 392]\n",
      " [330 658]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_semi_supervised(X, y, iterations=10, confidence_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Train a semi-supervised Decision Tree model.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix \n",
    "    - y: Label vector \n",
    "    - iterations: Number of iterations for pseudo-labeling\n",
    "    - confidence_threshold: Minimum confidence probability for pseudo-labeling\n",
    "\n",
    "    Returns:\n",
    "    - Final trained Decision Tree model\n",
    "    \"\"\"\n",
    "    \n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(\n",
    "        X_grey_train, y_grey_train, test_size=0.8, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print(f\"\\n Iteration {i+1}: Training on {len(X_labeled)} labeled samples.\")\n",
    "\n",
    "        \n",
    "        dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=42)\n",
    "        dt_model.fit(X_labeled, y_labeled)\n",
    "\n",
    "        \n",
    "        y_pseudo_probs = dt_model.predict_proba(X_unlabeled)\n",
    "        y_pseudo_labels = dt_model.predict(X_unlabeled)\n",
    "        accuracy_train = accuracy_score(y_unlabeled, y_pseudo_labels)\n",
    "        cm_train_xgb = confusion_matrix(y_unlabeled, y_pseudo_labels)\n",
    "        print(f\" Test Accuracy after Iteration {i+1}: {accuracy_train:.4f}\")\n",
    "        print(\"Classification Report:\\n\", classification_report(y_unlabeled, y_pseudo_labels, target_names=classification_targets))\n",
    "        print(f\" Test Confusion Matrix after Iteration {i+1}:\\n\", cm_train_xgb)\n",
    "\n",
    "\n",
    "        \n",
    "        high_confidence_mask = (y_pseudo_probs.max(axis=1) >= confidence_threshold)\n",
    "        confident_indices = np.where(high_confidence_mask)[0]  # Get indices\n",
    "\n",
    "        if len(confident_indices) == 0:\n",
    "            print(\"No confident pseudo-labels found. Stopping early.\")\n",
    "            break\n",
    "\n",
    "        X_labeled = np.vstack((X_labeled, X_unlabeled[confident_indices]))\n",
    "        y_labeled = np.hstack((y_labeled, y_pseudo_labels[confident_indices]))\n",
    "\n",
    "        X_unlabeled = np.delete(X_unlabeled, confident_indices, axis=0)\n",
    "        y_unlabeled = np.delete(y_unlabeled, confident_indices)\n",
    "\n",
    "        print(f\"{len(confident_indices)} high-confidence samples added. New labeled size: {len(X_labeled)}\")\n",
    "\n",
    "        # y_train_pred = dt_model.predict(X_labeled)\n",
    "        # accuracy_train = accuracy_score(y_labeled, y_train_pred)\n",
    "        # cm_train_xgb = confusion_matrix(y_labeled, y_train_pred)\n",
    "        \n",
    "\n",
    "\n",
    "        # print(f\" Training Accuracy after Iteration {i+1}: {accuracy_train:.4f}\")\n",
    "        # print(\"Classification Report:\\n\", classification_report(y_labeled, y_train_pred, target_names=classification_targets))\n",
    "        # print(f\" Training Confusion Matrix after Iteration {i+1}:\\n\", cm_train_xgb)\n",
    "\n",
    "    # **Final Step: Train Decision Tree on Fully Labeled Data**\n",
    "    # print(\"\\nTraining Final Decision Tree on Fully Labeled Data...\")\n",
    "    # dt_model_final = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "    # dt_model_final.fit(X_labeled, y_labeled)\n",
    "    \n",
    "    return dt_model\n",
    "\n",
    "dt_model_semi_supervised = train_semi_supervised(X_grey_train, y_grey_train)\n",
    "\n",
    "y_test_pred = dt_model_semi_supervised.predict(X_grey_test)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_grey_test, y_test_pred)\n",
    "cm_train_xgb = confusion_matrix(y_grey_test, y_test_pred)\n",
    "# cm_test = confusion_matrix(y_grey_test, y_test_pred)\n",
    "\n",
    "print(\"\\nFinal Testing Metrics\")\n",
    "print(f'Accuracy: {accuracy_test:.4f}')\n",
    "print(\"Classification Report:\\n\", classification_report(y_grey_test, y_test_pred, target_names=classification_targets))\n",
    "print('Confusion Matrix:\\n', cm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dt_model_semi_supervised_grey.pkl\", \"wb\") as dt_model_semi_supervised_grey_file:\n",
    "    pickle.dump(dt_model_semi_supervised, dt_model_semi_supervised_grey_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
